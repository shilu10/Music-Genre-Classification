{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:34.490694Z","iopub.status.busy":"2023-05-03T12:43:34.489758Z","iopub.status.idle":"2023-05-03T12:43:34.498468Z","shell.execute_reply":"2023-05-03T12:43:34.497407Z","shell.execute_reply.started":"2023-05-03T12:43:34.490639Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import os\n","import ast\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import IPython.display as ipd\n","from sklearn.decomposition import PCA \n","from sklearn.preprocessing import *\n","import numpy as np\n","\n","from sklearn.feature_selection import *\n","import librosa\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:34.538916Z","iopub.status.busy":"2023-05-03T12:43:34.538601Z","iopub.status.idle":"2023-05-03T12:43:34.543970Z","shell.execute_reply":"2023-05-03T12:43:34.542799Z","shell.execute_reply.started":"2023-05-03T12:43:34.538872Z"},"trusted":true},"outputs":[],"source":["# paths for the data\n","\n","DATA_PATH = \"/kaggle/input/fma-small/\"\n","METADATA_PATH = DATA_PATH + \"fma_metadata/fma_metadata/\"\n","FMA_SMALL_PATH = DATA_PATH + \"fma_small/fma_small/\"\n","FIG_SIZE = (20, 20)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:34.618857Z","iopub.status.busy":"2023-05-03T12:43:34.618577Z","iopub.status.idle":"2023-05-03T12:43:34.642650Z","shell.execute_reply":"2023-05-03T12:43:34.641661Z","shell.execute_reply.started":"2023-05-03T12:43:34.618830Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['echonest.csv',\n"," 'raw_genres.csv',\n"," 'raw_artists.csv',\n"," 'features.csv',\n"," 'genres.csv',\n"," 'README.txt',\n"," 'not_found.pickle',\n"," 'tracks.csv',\n"," 'raw_tracks.csv',\n"," 'raw_albums.csv',\n"," 'raw_echonest.csv',\n"," 'checksums']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["os.listdir(METADATA_PATH)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:34.699279Z","iopub.status.busy":"2023-05-03T12:43:34.698652Z","iopub.status.idle":"2023-05-03T12:43:34.710169Z","shell.execute_reply":"2023-05-03T12:43:34.709187Z","shell.execute_reply.started":"2023-05-03T12:43:34.699241Z"},"trusted":true},"outputs":[],"source":["def load(filepath):\n","\n","    filename = os.path.basename(filepath)\n","\n","    if 'features' in filename:\n","        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n","\n","    if 'echonest' in filename:\n","        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n","\n","    if 'genres' in filename:\n","        return pd.read_csv(filepath, index_col=0)\n","\n","    if 'tracks' in filename:\n","        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n","\n","        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n","                   ('track', 'genres'), ('track', 'genres_all'),\n","                   ('track', 'genres_top')]\n","        for column in COLUMNS:\n","            tracks[column] = tracks[column].map(ast.literal_eval)\n","\n","        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n","                   ('album', 'date_created'), ('album', 'date_released'),\n","                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n","                   ('artist', 'active_year_end')]\n","        for column in COLUMNS:\n","            tracks[column] = pd.to_datetime(tracks[column])\n","\n","        SUBSETS = ('small', 'medium', 'large')\n","        tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n","                'category', categories=SUBSETS, ordered=True)\n","\n","        COLUMNS = [('track', 'license'), ('artist', 'bio'),\n","                   ('album', 'type'), ('album', 'information')]\n","        for column in COLUMNS:\n","            tracks[column] = tracks[column].astype('category')\n","\n","        return tracks"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Creaing npz files for train, test, val data**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:23.821299Z","iopub.status.busy":"2023-05-03T12:43:23.820487Z","iopub.status.idle":"2023-05-03T12:43:23.829129Z","shell.execute_reply":"2023-05-03T12:43:23.827952Z","shell.execute_reply.started":"2023-05-03T12:43:23.821256Z"},"trusted":true},"outputs":[],"source":["def get_audio_path(audio_dir, track_id):\n","    \"\"\"\n","    Return the path to the mp3 given the directory where the audio is stored\n","    and the track ID.\n","    Examples\n","    \n","    --------\n","    >>> import utils\n","    >>> AUDIO_DIR = os.environ.get('AUDIO_DIR')\n","    >>> utils.get_audio_path(AUDIO_DIR, 2)\n","    '../data/fma_small/000/000002.mp3'\n","    \"\"\"\n","    try:\n","        tid_str = '{:06d}'.format(track_id)\n","        return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n","    \n","    except Exception as err:\n","        return err\n","\n","def create_spectogram(dir_path , track_id):\n","    \"\"\"\n","        this function, will create a melspectrogram from the signal.\n","        Params:\n","            dir_path(type: str): Path to the main directory, where it contains, the music files like (.wav, .mp3).\n","            track_id(type: Int): Each row in the dataframe, have a track_id, which map to the music file.\n","        Return(type: np.NdArray)\n","            this function, will return the melspectrogram data.\n","    \"\"\"\n","    try:\n","        filepath = get_audio_path(dir_path, track_id)\n","        y, sr = librosa.load(filepath)\n","        spect = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=2048, hop_length=1024)\n","        spect = librosa.power_to_db(spect, ref=np.max)\n","        return spect.T\n","\n","    except Exception as err:\n","        return err"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:23.979695Z","iopub.status.busy":"2023-05-03T12:43:23.978679Z","iopub.status.idle":"2023-05-03T12:43:23.987779Z","shell.execute_reply":"2023-05-03T12:43:23.986757Z","shell.execute_reply.started":"2023-05-03T12:43:23.979649Z"},"trusted":true},"outputs":[],"source":["def get_combined_df(): \n","    \"\"\"\n","        this function, will create a combined.\n","        PArams:(none)\n","        Return (type: pd.DataFrame)\n","    \"\"\"\n","    try:\n","        filepath = METADATA_PATH + \"tracks.csv\"\n","        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n","        keep_cols = [('set', 'split'),\n","        ('set', 'subset'),('track', 'genre_top')]\n","\n","        df_all = tracks[keep_cols]\n","        df_all = df_all[df_all[('set', 'subset')] == 'small']\n","\n","        df_all['track_id'] = df_all.index\n","        \n","        return df_all \n","    \n","    except Exception as err:\n","        return err\n","\n","def get_processing_data(df): \n","    \"\"\"\n","        this function, will get the training, testing and validation subset data from the dataframe.\n","        Params:\n","            df(type: pandas.DataFrame): DataFrame, that contains the data.\n","        Return(type: pd.DataFrame, pd.DataFrame, pd.DataFrame)\n","            this function, will return the train, test, val dataframes.\n","    \"\"\"\n","    try:\n","        train = df[df['set', 'split'] == 'training']\n","        val = df[df['set', 'split'] == 'validation']\n","        test = df[df['set', 'split'] == 'test']\n","        \n","        return train, val, test\n","    \n","    except Exception as error:\n","        return error"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:24.148934Z","iopub.status.busy":"2023-05-03T12:43:24.148572Z","iopub.status.idle":"2023-05-03T12:43:24.154128Z","shell.execute_reply":"2023-05-03T12:43:24.153083Z","shell.execute_reply.started":"2023-05-03T12:43:24.148879Z"},"trusted":true},"outputs":[],"source":["def create_label_map(labels): \n","    \"\"\"\n","        this function, will create a dictionary with the key as a integer value and value of dictionary as \n","        a label. (similar to the label encoding). this function creates two dictionary one for mapping integer to the label\n","        and another maps label to the integer\n","        eg:\n","            label_map = {\n","                'cat': 0\n","            }\n","            reverse_label_map = [\n","                0: 'cat'\n","            ]\n","        Params;\n","            labels(type: List): list containing all the label categories.\n","        Return(type: Dict, Dict)\n","            this function, will return the dictionary of labels and integet mapping and integer and label mapping.\n","    \"\"\"\n","    try:\n","        label_map = {}\n","        reverse_label_map = {}\n","        for indx, val in enumerate(labels): \n","            label_map[val] = indx \n","            reverse_label_map[indx] = val\n","        \n","        return label_map, reverse_label_map\n","    \n","    except Exception as error:\n","        return error"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## **Function for creating a training data.**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Function for creating Mel Spectrogram data**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:24.447385Z","iopub.status.busy":"2023-05-03T12:43:24.446696Z","iopub.status.idle":"2023-05-03T12:43:24.464282Z","shell.execute_reply":"2023-05-03T12:43:24.463241Z","shell.execute_reply.started":"2023-05-03T12:43:24.447346Z"},"trusted":true},"outputs":[],"source":["import tqdm \n","\n","def create_melspectrogram_data(df, dir_path, label_map):\n","    \"\"\"\n","        - this function, will create a training data with melspectrogram feature. for each audio we will extract\n","        the melspectrogram feature(2-Dimension) data. We will add a extra index at the end to convert it into 3D data.\n","        And it also uses the create_spectogram function to extract the mel spectrogram for each audio file.\n","        - Params:\n","            df(type: pd.DataFrame): FMA dataframe.\n","            dir_path(type: str): Path to the main directory, where it contains, the music files like (.wav, .mp3).\n","            label_map(type: Dict): label_map, which is nothing but a mapping of label to the integer value,\n","        - Return(type: (np.ndarray, np.array))\n","            this function, will return X and label data, which will be used to trained a Neural Network.\n","    \"\"\"\n","    X = np.empty((0, 640, 128))\n","    y = []\n","    for i in tqdm.tqdm(range(len(df))): \n","        try: \n","            if i >= 5000:\n","                break \n","            track_id = df[\"track_id\"].iloc[i]\n","            genre_type = df[(\"track\", \"genre_top\")].iloc[i]\n","            spect = create_spectogram(dir_path, track_id)\n","            \n","            spect = spect[:640, :]\n","            X = np.append(X, [spect], axis=0)\n","            \n","        except Exception as error:\n","            continue \n","            \n","        else: \n","            y.append(label_map[genre_type])\n","            \n","    return X, np.array(y)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Function for creating MFCC data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def create_mfcc_data(df, dir_path, label_map):\n","     \"\"\"\n","        - this function, will create a training data with MFCC(Mel-frequency cepstral coefficients) feature. \n","        for each audio we will extract the melspectrogram feature(2-Dimension) data. We will add a extra index \n","        at the end to convert it into 3D data. And it also uses the create_spectogram function to extract the mel \n","        spectrogram for each audio file.\n","        - Params:\n","            df(type: pd.DataFrame): FMA dataframe.\n","            dir_path(type: str): Path to the main directory, where it contains, the music files like (.wav, .mp3).\n","            label_map(type: Dict): label_map, which is nothing but a mapping of label to the integer value,\n","        - Return(type: (np.ndarray, np.array))\n","            this function, will return X and label data, which will be used to trained a Neural Network.\n","    \"\"\"\n","    X = np.empty((0, 13, 1280))\n","    y = []\n","    for i in tqdm.tqdm(range(len(df))): \n","        try: \n","            if i >= 5000:\n","                break \n","            track_id = df[\"track_id\"].iloc[i]\n","            genre_type = df[(\"track\", \"genre_top\")].iloc[i]\n","            \n","            filepath = get_audio_path(dir_path, track_id)\n","            signal, sample_rate = librosa.load(filepath, sr=22050)\n","            hop_length = 512\n","            n_fft = 2048 \n","            hop_length_duration = float(hop_length)/sample_rate\n","            n_fft_duration = float(n_fft)/sample_rate\n","            mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n","         #   mfcc = np.moveaxis(mfcc, 0, 1)\n","            mfcc = mfcc[:, :1280]\n","            X = np.append(X, [mfcc], axis=0)\n","        \n","        except Exception as error:Mel-frequency cepstral coefficients\n","            continue\n","            \n","        else:\n","            y.append(label_map[genre_type])\n","            \n","    return X, np.array(y)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Function for creating Chromogram data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_chromagram_data(df, dir_path, label_map):\n","    \"\"\"\n","        - this function, will create a training data with Chromagram feature. for each audio we will extract \n","        the melspectrogram feature(2-Dimension) data. We will add a extra index at the end to convert it into \n","        3D data. And it also uses the create_spectogram function to extract the mel spectrogram for each audio file.\n","        - Params:\n","            df(type: pd.DataFrame): FMA dataframe.\n","            dir_path(type: str): Path to the main directory, where it contains, the music files like (.wav, .mp3).\n","            label_map(type: Dict): label_map, which is nothing but a mapping of label to the integer value,\n","        - Return(type: (np.ndarray, np.array))\n","            this function, will return X and label data, which will be used to trained a Neural Network.\n","    \"\"\"\n","    X = np.empty((0, 13, 1280))\n","    y = []\n","    for i in tqdm.tqdm(range(len(df))): \n","        try: \n","            if i >= 5000:\n","                break \n","            track_id = df[\"track_id\"].iloc[i]\n","            genre_type = df[(\"track\", \"genre_top\")].iloc[i]\n","            \n","            filepath = get_audio_path(dir_path, track_id)\n","            signal, sample_rate = librosa.load(filepath, sr=22050)\n","            chroma_stft = librosa.feature.chroma_stft(y=signal, sr=sample_rate, n_chroma=13, n_fft=4096)\n","            \n","            chroma_stft = chroma_stft[:, :1280]\n","            X = np.append(X, [chroma_stft], axis=0)\n","        \n","        except Exception as error:\n","            continue\n","            \n","        else:\n","            y.append(label_map[genre_type])\n","            \n","    return X, np.array(y)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Function for creating Ensemble data**"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:24.524721Z","iopub.status.busy":"2023-05-03T12:43:24.523843Z","iopub.status.idle":"2023-05-03T12:43:24.536101Z","shell.execute_reply":"2023-05-03T12:43:24.534900Z","shell.execute_reply.started":"2023-05-03T12:43:24.524678Z"},"trusted":true},"outputs":[],"source":["\n","def padding(array, xx, yy):\n","    \"\"\"\n","        this function, will create a ensemble data, that will be used to train the neural network, this ensemble of \n","        data contains, multiple features from the audio like spectral centroids, mfcc, melspec, chromogram, etc.\n","        :param array: numpy array\n","        :param xx: desired height\n","        :param yy: desirex width\n","        :return: padded array\n","    \"\"\"\n","    h = array.shape[0]\n","    w = array.shape[1]\n","    a = max((xx - h) // 2,0)\n","    aa = max(0,xx - a - h)\n","    b = max(0,(yy - w) // 2)\n","    bb = max(yy - b - w,0)\n","    return np.pad(array, pad_width=((a, aa), (b, bb)), mode='constant')\n","\n","\n","def generate_features(y_cut, sr):\n","    max_size=1291 #my max audio file feature width\n","    stft = padding(np.abs(librosa.stft(y=y_cut, n_fft=255, hop_length        = 512)), 128, max_size)\n","    MFCCs = padding(librosa.feature.mfcc(y=y_cut, n_fft=255, hop_length=512,n_mfcc=128),128,max_size)\n","    spec_centroid = librosa.feature.spectral_centroid(y=y_cut, sr=sr)\n","    chroma_stft = librosa.feature.chroma_stft(y=y_cut, sr=sr)\n","    spec_bw = librosa.feature.spectral_bandwidth(y=y_cut, sr=sr)\n","    #Now the padding part\n","    image = np.array([padding(normalize(spec_bw),1, max_size)]).reshape(1,max_size)\n","    image = np.append(image,padding(normalize(spec_centroid),1, max_size), axis=0) \n","    \n","    print(image, \"i\")\n","    #repeat the padded spec_bw,spec_centroid and chroma stft until they are stft and MFCC-sized\n","    for i in range(0,9):\n","        image = np.append(image,padding(normalize(spec_bw),1, max_size), axis=0)\n","        image = np.append(image, padding(normalize(spec_centroid),1, max_size), axis=0)\n","        image = np.append(image, padding(normalize(chroma_stft),12, max_size), axis=0)\n","    image=np.dstack((image,np.abs(stft)))\n","    image=np.dstack((image,MFCCs))\n","    return image\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## **Creating Training, Testing and Validation DataFrame from the FMA dataframe(subset: small)**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T12:43:42.870619Z","iopub.status.busy":"2023-05-03T12:43:42.869942Z","iopub.status.idle":"2023-05-03T12:43:48.588500Z","shell.execute_reply":"2023-05-03T12:43:48.586638Z","shell.execute_reply.started":"2023-05-03T12:43:42.870580Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number training samples: 6400\n","Number validation samples: 800\n","Number testomg samples: 800\n"]}],"source":["combined_df = get_combined_df()\n","train, val, test = get_processing_data(combined_df)\n","\n","genres = np.unique(train[(\"track\", \"genre_top\")])\n","label_map, rev_label_map = create_label_map(genres)\n","label_map\n","\n","print(f\"Number training samples: {train.shape[0]}\")\n","print(f\"Number validation samples: {val.shape[0]}\")\n","print(f\"Number testomg samples: {test.shape[0]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from concurrent.futures import ProcessPoolExecutor\n","\n","def use_multiprocessing(): \n","    data = [(train, FMA_SMALL_PATH, label_map), (val, FMA_SMALL_PATH, label_map), (test, FMA_SMALL_PATH, label_map)]\n","    with ProcessPoolExecutor() as executor:\n","        futures = [executor.submit(create_melspectrogram_data, d[0], d[1], d[2]) for d in data]\n","        results = [result.result() for result in futures]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Creating a Mel-Spectrogram data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mel_train_X, mel_train_y = create_melspectrogram_data(train, FMA_SMALL_PATH, label_map)\n","mel_val_X, mel_val_y = create_melspectrogram_data(val, FMA_SMALL_PATH, label_map)\n","mel_test_X, mel_test_y = create_melspectrogram_data(test, FMA_SMALL_PATH, label_map)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Creating MFCC data**"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T04:06:19.867667Z","iopub.status.busy":"2023-05-01T04:06:19.867285Z","iopub.status.idle":"2023-05-01T04:17:31.423416Z","shell.execute_reply":"2023-05-01T04:17:31.421799Z","shell.execute_reply.started":"2023-05-01T04:06:19.867634Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 800/800 [05:31<00:00,  2.41it/s]\n","100%|██████████| 800/800 [05:40<00:00,  2.35it/s]\n"]}],"source":["mfcc_train_X, mfcc_train_y = create_mfcc_data(train, FMA_SMALL_PATH, label_map)\n","mfcc_test_X, mfcc_test_y = create_mfcc_data(test, FMA_SMALL_PATH, label_map)\n","mfcc_val_X, mfcc_val_y = create_mfcc_data(val, FMA_SMALL_PATH, label_map)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Creating Chromogram data**"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T11:59:26.502512Z","iopub.status.busy":"2023-05-01T11:59:26.501844Z","iopub.status.idle":"2023-05-01T12:12:53.161180Z","shell.execute_reply":"2023-05-01T12:12:53.157265Z","shell.execute_reply.started":"2023-05-01T11:59:26.502475Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 800/800 [06:50<00:00,  1.95it/s]\n","100%|██████████| 800/800 [06:35<00:00,  2.02it/s]\n"]}],"source":["chroma_train_X, chroma_train_y = create_chromagram_data(train, FMA_SMALL_PATH, label_map)\n","chroma_test_X, chroma_test_y = create_chromagram_data(test, FMA_SMALL_PATH, label_map)\n","chroma_val_X, chroma_val_y = create_chromagram_data(val, FMA_SMALL_PATH, label_map)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Creating Ensemble data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["en_train_X, en_train_y = generate_ensemble_features(train, FMA_SMALL_PATH, label_map)\n","en_test_X, en_test_y = generate_ensemble_features(test, FMA_SMALL_PATH, label_map)\n","en_val_X, en_val_y = generate_ensemble_features(val, FMA_SMALL_PATH, label_map)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Converting the np arrays of the data into npz compressed files**"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T12:16:22.242495Z","iopub.status.busy":"2023-05-01T12:16:22.241446Z","iopub.status.idle":"2023-05-01T12:16:22.248230Z","shell.execute_reply":"2023-05-01T12:16:22.246712Z","shell.execute_reply.started":"2023-05-01T12:16:22.242445Z"},"trusted":true},"outputs":[],"source":["def create_compressed_File(data_X, data_y, X_type, type_of_data): \n","    \"\"\"\n","        this function, will convert the numpy array into file.\n","        Params:\n","            data_X(type: np.ndarray): X(independent data).\n","            data_y(type: np.array): y(dependent data).\n","            X_type(type: str): Which type of audio feature(eg: mfcc, mel-spectrogram).\n","            type_of_data(type: str): tpye of data (eg: train, test or val).\n","        Return(type: None)\n","    \"\"\"\n","    filename = f\"{X_type}-{type_of_data}\"\n","    np.savez_compressed(filename, X=data_X, y = data_y)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Saving MelSpectrogram data**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["create_compressed_File(mel_train_X, mel_train_y, \"melspectrogram\", 'train')\n","create_compressed_File(mel_val_X, mel_val_y, \"melspectrogram\", 'val')\n","create_compressed_File(mel_test_X, mel_test_y, \"melspectrogram\", 'test')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Saving MFCC (Mel-frequency cepstral coefficients) data**"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2023-04-27T08:57:04.079911Z","iopub.status.busy":"2023-04-27T08:57:04.078522Z","iopub.status.idle":"2023-04-27T08:57:32.083866Z","shell.execute_reply":"2023-04-27T08:57:32.082477Z","shell.execute_reply.started":"2023-04-27T08:57:04.079860Z"},"trusted":true},"outputs":[],"source":["create_compressed_File(mfcc_train_X, mfcc_train_y, \"mfcc\", 'train')\n","create_compressed_File(mfcc_val_X, mfcc_val_y, \"mfcc\", 'val')\n","create_compressed_File(mfcc_test_X, mfcc_test_y, \"mfcc\", 'test')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Saving MFCC (Mel-frequency cepstral coefficients) No Moving Axis data**"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T04:19:41.613210Z","iopub.status.busy":"2023-05-01T04:19:41.611989Z","iopub.status.idle":"2023-05-01T04:20:07.137875Z","shell.execute_reply":"2023-05-01T04:20:07.136628Z","shell.execute_reply.started":"2023-05-01T04:19:41.613147Z"},"trusted":true},"outputs":[],"source":["create_compressed_File(mfcc_train_X, mfcc_train_y, \"mfcc-nomoveaxis\", 'train')\n","create_compressed_File(mfcc_val_X, mfcc_val_y, \"mfcc-nomoveaxis\", 'val')\n","create_compressed_File(mfcc_test_X, mfcc_test_y, \"mfcc-nomoveaxis\", 'test')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Saving Chromogram data**"]},{"cell_type":"code","execution_count":122,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T10:15:37.994376Z","iopub.status.busy":"2023-05-01T10:15:37.993650Z","iopub.status.idle":"2023-05-01T10:16:49.382242Z","shell.execute_reply":"2023-05-01T10:16:49.381041Z","shell.execute_reply.started":"2023-05-01T10:15:37.994337Z"},"trusted":true},"outputs":[],"source":["create_compressed_File(chroma_train_X, chroma_train_y, \"chroma\", 'train')\n","create_compressed_File(chroma_test_X, chroma_test_y, \"chroma\", 'test')\n","create_compressed_File(chroma_val_X, chroma_val_y, \"chroma\", 'val')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **Saving Ensemble Feature data**"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T12:16:26.051301Z","iopub.status.busy":"2023-05-01T12:16:26.050591Z","iopub.status.idle":"2023-05-01T12:16:49.623780Z","shell.execute_reply":"2023-05-01T12:16:49.622748Z","shell.execute_reply.started":"2023-05-01T12:16:26.051264Z"},"trusted":true},"outputs":[],"source":["create_compressed_File(en_train_X, en_train_y, \"ensemble\", 'train')\n","create_compressed_File(en_test_X, en_test_y, \"ensemble\", 'test')\n","create_compressed_File(en_val_X, en_val_y, \"ensemble\", 'val')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
